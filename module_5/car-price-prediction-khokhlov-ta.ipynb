{"cells":[{"metadata":{"papermill":{"duration":0.029718,"end_time":"2020-10-26T12:46:41.276296","exception":false,"start_time":"2020-10-26T12:46:41.246578","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Прогнозирование стоимости автомобиля по характеристикам"},{"metadata":{},"cell_type":"markdown","source":"## Подключаем библиотеки"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-10-26T12:46:41.400302Z","iopub.status.busy":"2020-10-26T12:46:41.399317Z","iopub.status.idle":"2020-10-26T12:46:42.581426Z","shell.execute_reply":"2020-10-26T12:46:42.580431Z"},"papermill":{"duration":1.219772,"end_time":"2020-10-26T12:46:42.581597","exception":false,"start_time":"2020-10-26T12:46:41.361825","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import re\nimport sys\nimport ast\nimport json\nimport numpy as np\nimport pandas as pd\nimport requests\nimport pandas.api.types as at\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import defaultdict\nfrom bs4 import BeautifulSoup\nfrom datetime import timedelta, datetime, date\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True) \n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom catboost import CatBoostRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-10-26T12:46:42.646795Z","iopub.status.busy":"2020-10-26T12:46:42.645765Z","iopub.status.idle":"2020-10-26T12:46:42.649793Z","shell.execute_reply":"2020-10-26T12:46:42.650407Z"},"papermill":{"duration":0.040034,"end_time":"2020-10-26T12:46:42.650603","exception":false,"start_time":"2020-10-26T12:46:42.610569","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-10-26T12:46:42.716039Z","iopub.status.busy":"2020-10-26T12:46:42.715184Z","iopub.status.idle":"2020-10-26T12:46:47.852433Z","shell.execute_reply":"2020-10-26T12:46:47.851661Z"},"papermill":{"duration":5.172536,"end_time":"2020-10-26T12:46:47.852593","exception":false,"start_time":"2020-10-26T12:46:42.680057","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:46:47.919419Z","iopub.status.busy":"2020-10-26T12:46:47.918168Z","iopub.status.idle":"2020-10-26T12:46:47.922267Z","shell.execute_reply":"2020-10-26T12:46:47.921365Z"},"papermill":{"duration":0.039842,"end_time":"2020-10-26T12:46:47.922434","exception":false,"start_time":"2020-10-26T12:46:47.882592","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def mape(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)/y_true))","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:46:48.05046Z","iopub.status.busy":"2020-10-26T12:46:48.049412Z","iopub.status.idle":"2020-10-26T12:46:48.052578Z","shell.execute_reply":"2020-10-26T12:46:48.051917Z"},"papermill":{"duration":0.039969,"end_time":"2020-10-26T12:46:48.052728","exception":false,"start_time":"2020-10-26T12:46:48.012759","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"VERSION    = 4\nDIR_TRAIN  = '../input/autoru-04032021/' # подключил к ноутбуку внешний датасет\nDIR_TEST   = '../input/sf-dst-car-price-prediction/'\nVAL_SIZE   = 0.20   # 20%\n\npd.set_option('display.max_columns', 50)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.030254,"end_time":"2020-10-26T12:46:48.112586","exception":false,"start_time":"2020-10-26T12:46:48.082332","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 1. Данные"},{"metadata":{},"cell_type":"markdown","source":"## 1.1 Загрузка данных"},{"metadata":{},"cell_type":"markdown","source":"Тренировочный датасет я подготовил на локальной машине. Сюда прикладываю закомментированный код, который формирует файл \"autoru_02032021.csv\""},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"Функция сбора данных с объявления на auto.ru\n   На вход получает ссылку на объявление\n   На выходе - словарь с собранными данными\"\"\"\n\n# def car_detail(url):\n#     response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n#     response.encoding = 'utf-8'\n#     soup = BeautifulSoup(response.text, 'html.parser')\n#     url_dict = {}\n#     \n#     if 'Этот автомобиль уже продан' in soup.text:\n#         return url_dict\n#     \n#     # Изучив предложенные тестовые и тренировочные данные, а также html страницу с объявлениями\n#     # я нашел, что большая часть информации об автомобиле находится\n#     # в тегах 'script' с type='application/ld+json'\n#     \n#     try:\n#         json_page_1 = json.loads(soup.find_all('script', attrs = {'type':'application/ld+json'})[0].text)\n#         json_page_2 = json.loads(soup.find_all('script', attrs = {'type':'application/ld+json'})[1].text)\n#         json_page_3 = json.loads(soup.find('div', attrs = {'id': 'sale-data-attributes'}).attrs['data-bem'])\n#         \n#     except(KeyError, IndexError):\n#         return url_dict\n# \n#     try:\n#         url_dict['car_url'] = url\n# \n#         url_dict['bodyType'] = json_page_1['bodyType']\n#         url_dict['brand'] = json_page_1['brand']\n#         url_dict['color'] = json_page_1['color']\n#         url_dict['description'] = json_page_1['description']\n#         url_dict['modelDate'] = json_page_1['modelDate']\n#         url_dict['numberOfDoors'] = json_page_1['numberOfDoors']\n#         url_dict['productionDate'] = json_page_1['productionDate']\n#         url_dict['numberOfDoors'] = json_page_1['numberOfDoors']\n#         url_dict['vehicleConfiguration'] = json_page_1['vehicleConfiguration']\n#         url_dict['vehicleTransmission'] = json_page_1['vehicleTransmission']\n#         url_dict['image'] = json_page_1['image']\n#         url_dict['engineDisplacement'] = json_page_1['vehicleEngine']['engineDisplacement']\n#         url_dict['enginePower'] = json_page_1['vehicleEngine']['enginePower']\n#         url_dict['fuelType'] = json_page_1['vehicleEngine']['fuelType']\n#         url_dict['price'] = int(json_page_1['offers']['price'])\n#         url_dict['priceCurrency'] = json_page_1['offers']['priceCurrency']\n# \n#         url_dict['name'] = json_page_2['itemListElement'][3]['name']\n# \n#         url_dict['model_name'] = json_page_3['sale-data-attributes']['model']\n#         url_dict['mileage'] = int(json_page_3['sale-data-attributes']['km-age'])\n# \n#         url_dict['Владельцы'] = soup.find('li', class_ = 'CardInfoRow CardInfoRow_ownersCount').find_all('span', class_='CardInfoRow__cell')[1].text.replace(u'\\xa0', u' ')\n#         url_dict['ПТС'] = soup.find('li', class_ = 'CardInfoRow CardInfoRow_pts').find_all('span', class_='CardInfoRow__cell')[1].text\n#         url_dict['Привод'] = soup.find('li', class_ = 'CardInfoRow CardInfoRow_drive').find_all('span', class_='CardInfoRow__cell')[1].text\n#         url_dict['Руль'] = soup.find('li', class_ = 'CardInfoRow CardInfoRow_wheel').find_all('span', class_='CardInfoRow__cell')[1].text\n#         url_dict['Таможня'] = soup.find('li', class_ = 'CardInfoRow CardInfoRow_customs').find_all('span', class_='CardInfoRow__cell')[1].text\n#         url_dict['Состояние'] = soup.find('li', class_ = 'CardInfoRow CardInfoRow_state').find_all('span', class_='CardInfoRow__cell')[1].text\n# \n#         complectation = []\n#         for complect in soup.find_all('li', class_='ComplectationGroups__itemContentEl'):\n#             complectation.append(complect.text)\n#         url_dict['complectation_dict'] = complectation\n#         \n#     except(KeyError, ValueError, AttributeError):\n#         pass\n#     \n#     return url_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# brands = ['bmw', 'volkswagen', 'nissan', 'mercedes', 'toyota', 'audi', \n#           'mitsubishi', 'skoda', 'volvo', 'honda', 'infiniti', 'lexus']\n# \n# # Собираем словарь, в котором сохраним ссылки на объявления по интересующим нас маркам автомобилей\n# \n# cars_urls = {}\n# url = 'https://auto.ru/cars/'\n# \n# for car_brand in brands:\n#     brand_url = url + car_brand + '/used/?page=' #собираем url для поиска по каждому бренду\n#     cars_urls[car_brand] = []\n#     \n#     for number in range(1, 100): # Опытным путем выяснили, что по каждому поиску отображается не более 100 страниц\n#         response = requests.get(brand_url+str(number), headers={'User-Agent': 'Mozilla/5.0'})\n#         page = BeautifulSoup(response.text, 'html.parser')\n#         link_list = page.find_all('a', class_='Link ListingItemTitle-module__link')\n#         \n#         if len(link_list) !=0: #если попытаемся перейти на страницу, которой не существует, то на ней просто не будет объявлений\n# \n#             for link in link_list:\n#                 cars_urls[car_brand].append(link['href'])\n#         \n#         else:\n#             break\n#     \n#     print('{}: Объявлений по марке {}: {}'.format(datetime.now(), car_brand, len(cars_urls[car_brand])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Запустим цикл, чтобы собрать по всем объявлениям детальную информацию\n# # и записать ее в DataFrame\n# \n# columns = ['bodyType', 'brand', 'car_url', 'color', 'complectation_dict',\n#       'description', 'engineDisplacement', 'enginePower', 'equipment_dict',\n#       'fuelType', 'image', 'mileage', 'modelDate', 'model_info', 'model_name',\n#       'name', 'numberOfDoors', 'parsing_unixtime', 'priceCurrency',\n#       'productionDate', 'sell_id', 'super_gen', 'vehicleConfiguration',\n#       'vehicleTransmission', 'vendor', 'Владельцы', 'Владение', 'ПТС',\n#        'Привод', 'Руль', 'Состояние', 'Таможня', 'price']\n# df_train = pd.DataFrame(columns=columns)\n# \n# print('Старт {}'.format(datetime.now()))\n# \n# for car_brand in brands:\n#     counter = 0\n#     \n#     for car_url in cars_urls[car_brand]:\n#         counter += 1\n#         df_train.loc[len(df_train)] = pd.Series(car_detail(car_url))\n#         \n#         if counter == len(cars_urls[car_brand])//4:\n#             print('{}: Четверть ссылок по марке {} обработана'.format(datetime.now(), car_brand))\n#         \n#         if counter == len(cars_urls[car_brand])//2:\n#             print('{}: Половина ссылок по марке {} обработана'.format(datetime.now(), car_brand))\n#         \n#         if counter == len(cars_urls[car_brand]):\n#             print('{}: Все ссылки по марке {} обработаны'.format(datetime.now(), car_brand))\n# \n# print('Конец {}'.format(datetime.now()))\n# \n# # В полученном датафрейме удалим пустые строки\n# df_train.dropna(axis=0, how = 'all', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train.to_csv('autoru_02032021.csv')","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:46:48.179769Z","iopub.status.busy":"2020-10-26T12:46:48.178918Z","iopub.status.idle":"2020-10-26T12:46:48.924574Z","shell.execute_reply":"2020-10-26T12:46:48.925184Z"},"papermill":{"duration":0.783211,"end_time":"2020-10-26T12:46:48.925418","exception":false,"start_time":"2020-10-26T12:46:48.142207","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"!ls '../input'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-10-26T12:46:49.007668Z","iopub.status.busy":"2020-10-26T12:46:49.006762Z","iopub.status.idle":"2020-10-26T12:47:02.121152Z","shell.execute_reply":"2020-10-26T12:47:02.120434Z"},"papermill":{"duration":13.16556,"end_time":"2020-10-26T12:47:02.12133","exception":false,"start_time":"2020-10-26T12:46:48.95577","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train = pd.read_csv(DIR_TRAIN+'autoru_04032021.csv') # датасет для обучения модели\ntest = pd.read_csv(DIR_TEST+'test.csv')\nsample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:02.22557Z","iopub.status.busy":"2020-10-26T12:47:02.21916Z","iopub.status.idle":"2020-10-26T12:47:02.245921Z","shell.execute_reply":"2020-10-26T12:47:02.246559Z"},"papermill":{"duration":0.09378,"end_time":"2020-10-26T12:47:02.246755","exception":false,"start_time":"2020-10-26T12:47:02.152975","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train.sample(3).T","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:02.317036Z","iopub.status.busy":"2020-10-26T12:47:02.316251Z","iopub.status.idle":"2020-10-26T12:47:02.50135Z","shell.execute_reply":"2020-10-26T12:47:02.501985Z"},"papermill":{"duration":0.22352,"end_time":"2020-10-26T12:47:02.502166","exception":false,"start_time":"2020-10-26T12:47:02.278646","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:02.599966Z","iopub.status.busy":"2020-10-26T12:47:02.598892Z","iopub.status.idle":"2020-10-26T12:47:02.604335Z","shell.execute_reply":"2020-10-26T12:47:02.60353Z"},"papermill":{"duration":0.069985,"end_time":"2020-10-26T12:47:02.604497","exception":false,"start_time":"2020-10-26T12:47:02.534512","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"test.sample(3).T","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:02.7822Z","iopub.status.busy":"2020-10-26T12:47:02.781391Z","iopub.status.idle":"2020-10-26T12:47:02.797734Z","shell.execute_reply":"2020-10-26T12:47:02.798395Z"},"papermill":{"duration":0.160401,"end_time":"2020-10-26T12:47:02.798587","exception":false,"start_time":"2020-10-26T12:47:02.638186","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.033402,"end_time":"2020-10-26T12:47:02.866506","exception":false,"start_time":"2020-10-26T12:47:02.833104","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 1.2 Подготовка данных"},{"metadata":{},"cell_type":"markdown","source":"Выберем из train и test те колонки, которые, потенциально, можно будет использовать в модели.\nВ выборку не включаем следующие колонки:\n * **car_url** - ссылка на объявление, не несет полезной информации\n * **equipment_dict** - мне не удалось собрать аналогичную информацию для train. Да и в test в этой колонке перечислены комплектующие, которые также перечислены в complectation_dict\n * **image** - ссылка на картинку из обхявления, не несет полезной информации\n * **model_info** - дублирует информацию из model_name и name\n * **parsing_unixtime** - время загрузки объявления, не несет полезной информации\n * **priceCurrency** - и в train и в test имеет одно значение - RUB, не несет полезной информации\n * **sell_id** - id объявления, не несет полезной информации\n * **super_gen** - информацию о марке автомобиля, не смог добыть аналогичную информацию для train\n * **vehicleConfiguration** - дублирует информацию из model_name и vehicleTransmission\n * **vendor** - производитель автомобиля (европа или азия) не смог добыть аналогичную информацию для train\n * **Владение** - срок владения автомобилем, не смог добыть аналогичную информацию для train\n * **Состояние** - состояние автомобиля, везде одно значение - \"Не требует ремонта\", не несет полезной информации\n * **Таможня** - информация о том, растаможен ли автомобиль или нет, везде одно значение, не несет полезной информации"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = train[['bodyType', 'brand', 'color', 'complectation_dict', 'description', 'engineDisplacement',\n       'enginePower', 'fuelType', 'mileage', 'modelDate', 'model_name', 'name',\n       'numberOfDoors', 'productionDate', 'vehicleTransmission', \n       'Владельцы', 'ПТС', 'Привод', 'Руль', 'price']]\ndf_train.dropna(axis=0, how = 'all', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:02.941177Z","iopub.status.busy":"2020-10-26T12:47:02.94004Z","iopub.status.idle":"2020-10-26T12:47:02.94372Z","shell.execute_reply":"2020-10-26T12:47:02.943059Z"},"papermill":{"duration":0.042812,"end_time":"2020-10-26T12:47:02.943868","exception":false,"start_time":"2020-10-26T12:47:02.901056","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"df_test = test[['bodyType', 'brand', 'color', 'complectation_dict', 'description', 'engineDisplacement',\n       'enginePower', 'fuelType', 'mileage', 'modelDate', 'model_name', 'name',\n       'numberOfDoors', 'productionDate', 'vehicleTransmission', \n       'Владельцы', 'ПТС', 'Привод', 'Руль']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.1 bodyType"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удалим из train записи, у которых bodyType отличается от списка из test\nbody_type_list_test = list(df_test['bodyType'].unique())\n\ndef get_bodyType(x, body_type_list):\n    for t_bodyType in body_type_list:\n        if t_bodyType == x:\n            return t_bodyType\n        else: continue\n    return '0'\n    \ndf_train['bodyType'] = df_train['bodyType'].apply(lambda x: get_bodyType(x, body_type_list_test))\ndf_train = df_train[df_train['bodyType'] !='0']\ndf_train['bodyType'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.2 engineDisplacement"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Оставим в признаке только число\ndf_test['engineDisplacement'] = df_test['engineDisplacement'].apply(lambda x: str(x).replace('LTR', ''))\ndf_train['engineDisplacement'] = df_train['engineDisplacement'].apply(lambda x: str(x).replace('LTR', ''))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.3 enginePower"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Оставим в признаке только число\ndf_test['enginePower'] = df_test['enginePower'].apply(lambda x: 0 if str(x)[:-4] == '' else int(str(x)[:-4]))\ndf_train['enginePower'] = df_train['enginePower'].apply(lambda x: 0 if str(x)[:-4] == '' else int(str(x)[:-4]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.4 complectation_dict"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Распарсим стобец complectation_dict в test\ndef parse_test_complectation(value):\n    if value != value or pd.isnull(value):\n        return []\n    \n    json_complectation = json.loads(value)\n    values = json_complectation['available_options']\n    return values\n\ndf_test['complectation'] = df_test['complectation_dict'].apply(parse_test_complectation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Соберем все уникальные названия в признаке комплектации\ncomplectation_test = defaultdict(int)\n\nfor value in df_test['complectation']:\n    if value == value and value != None:\n        for item in value:\n            complectation_test[item] += 1\n\n# Выберем 30 наиболее часто встречающихся\nsort_complectation = sorted(complectation_test.items(), key = lambda x: x[1], reverse=True)\nmost_frequent_num = 30\nmost_frequent_items = []\n\nfor item in sort_complectation[:most_frequent_num]:\n    most_frequent_items.append(item[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(most_frequent_items)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Распарсим столбец complectation_dict в df_train\ndef parse_train_complectation(value):\n    if value != value or pd.isnull(value):\n        return []\n    \n    value = ast.literal_eval(value)\n    \n    # Составим словарь соответствия названий комплектующих на рускком (в train) и английском (в test)\n    # по самым часто встречающимся в test значениям \n    dict_components = {'Круиз-контроль':'cruise-control',\n                       'Противотуманные фары':'ptf',\n                       'Крепление детского кресла (задний ряд) ISOFIX':'isofix',\n                       'Отделка кожей рулевого колеса':'wheel-leather',\n                       'Подушки безопасности оконные (шторки)':'airbag-curtain',\n                       'AUX':'aux',\n                       'Третий задний подголовник':'third-rear-headrest',\n                       'Передний центральный подлокотник':'front-centre-armrest',\n                       'Система стабилизации (ESP)':'esp',\n                       'Антиблокировочная система (ABS)':'abs',\n                       'Подушка безопасности водителя':'airbag-driver',\n                       'Подушка безопасности пассажира':'airbag-passenger',\n                       'Электростеклоподъёмники передние':'electro-window-front',\n                       'Центральный замок':'lock',\n                       'Регулировка руля по вылету':'wheel-configuration1',\n                       'Регулировка руля по высоте':'wheel-configuration2',\n                       'Иммобилайзер':'immo',\n                       'Электрообогрев боковых зеркал':'mirrors-heat',\n                       'Электропривод зеркал':'electro-mirrors',\n                       'Аудиоподготовка':'audiopreparation',\n                       'Подогрев передних сидений':'front-seats-heat',\n                       'Складывающееся заднее сиденье':'seat-transformation',\n                       'Климат-контроль 1-зонный':'climate-control-1',\n                       'Кондиционер':'condition',\n                       'Бортовой компьютер':'computer',\n                       'Аудиосистема':'audiosystem-cd',\n                       'Электростеклоподъёмники задние':'electro-window-back',\n                       'Подушки безопасности боковые':'airbag-side',\n                       'Датчик дождя':'rain-sensor',\n                       'Мультифункциональное рулевое колесо':'multi-wheel'}\n    result = []\n    \n    for comp in value:\n        try:\n            result.append(dict_components[comp])\n        except(KeyError):\n            continue    \n   \n    return result\n\ndf_train['complectation'] = df_train['complectation_dict'].apply(parse_train_complectation)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.5 Владельцы"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Оставим только цифры\ndf_test['owners'] = df_test['Владельцы'].apply(lambda x: str(x).replace(u'\\xa0', u' ')).map({'3 или более':3, \n                                                                                             '2 владельца':2, \n                                                                                             '1 владелец':1})\n\ndf_train['owners'] = df_train['Владельцы'].apply(lambda x: str(x).replace(u'\\xa0', u' ')).map({'3 или более':3, \n                                                                                               '2 владельца':2, \n                                                                                               '1 владелец':1})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.6 Удаляем лишнее"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.drop(['complectation_dict', 'Владельцы'], axis=1, inplace=True)\ndf_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(['complectation_dict', 'Владельцы'], axis=1, inplace=True)\ndf_train.dropna(axis=0, inplace=True)\n\n# Поправим формат некоторых колонок для соответствия с test\ndf_train['modelDate'] = df_train['modelDate'].astype('int')\ndf_train['numberOfDoors'] = df_train['numberOfDoors'].astype('int')\ndf_train['mileage'] = df_train['mileage'].astype('int')\ndf_train['productionDate'] = df_train['productionDate'].astype('int')\ndf_train['owners'] = df_train['owners'].astype('int')\ndf_train['price'] = df_train['price'].astype('int')\n\ndf_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.3 Создаем новые признаки"},{"metadata":{},"cell_type":"markdown","source":"### 1.3.1 Объединяем датасеты"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Для корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3.2 Скорректируем значение признака engineDisplacement"},{"metadata":{},"cell_type":"markdown","source":"При обработке выборок я заметил, что чать значений в признаке engineDisplacement пропали (после очистки от 'LTR'). Исправим ситуацию, использовав данные из признака name. Также выделим из name информацию об автмобилях с гибридной силовой установкой"},{"metadata":{"trusted":true},"cell_type":"code","source":"pattern = re.compile('(\\d{1}\\.\\d{1})')\n\ndata['engine'] = data['name'].apply(lambda x:str(pattern.findall(str(x)))[2:5])\ndata['engine'] = pd.to_numeric(data['engine'], errors='coerce')\ndata['engine'].fillna(0, inplace=True) # Заполним пропуски нулями\ndata['engine'] = data['engine'].astype('int')\n\ndata['hybrid'] = data['name'].apply(lambda x: 1 if 'hyb' in x else 0)\n\n# Удалим дублирующую таблицу\ndata.drop(['engineDisplacement', 'name'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3.3 Тип продавца"},{"metadata":{},"cell_type":"markdown","source":"Информацию о типе продавца (реальный владелец или дилер) попробуем вытащить из описания"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['description'] = data['description'].map(lambda x: str(x).lower())\n\n# Чаще всего реальные владельцы авто пишут, что не нужнаются в перекупщиках и предлагают торг или обмен. \n# А так же мало пишут (маленькая длина объявления)\ndata['owner'] = data['description'].apply(lambda x: 1 if 'торг' in x \n                                          or 'не нуждаюсь' in x\n                                          or 'не беспокоить' in x\n                                          or 'обмен' in x\n                                          or 'Продаю' in x or 'продаю' in x\n                                          or len(x)<100 else 0)\n\n# Дилеры почти в каждом объявлении предлагаю кредит, тред-ид и прочие скидки\ndata['dealer'] = data['description'].apply(lambda x: 1 if 'traid-in' in x or 'трейд-ин' in x\n                                             or 'дилер' in x \n                                             or 'кредит' in x\n                                             or 'клиент' in x\n                                             or 'без комис' in x\n                                             or 'страховани' in x \n                                             or 'в наличии' in x \n                                             or 'выгодное пр' in x \n                                             or 'автокредит' in x \n                                             or 'рынке' in x or 'рынок' in x\n                                             else 0)\n\n# Так как ключевые слова для дилеров более явные, снимем флаг owner в тех строках, есть есть флаг dealer\ndata.loc[data['dealer'] == 1, 'owner'] = 0\n\n# Удалим описания из датасета\ndata.drop(['description'], axis=1, inplace=True)\n\ndisplay(data['owner'].value_counts())\ndisplay(data['dealer'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3.4 Создадим dummy-признаки из complectation"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\"Функция проверяет наличие item в переданном value\n    При этом, item является глобальной переменной для данной функции\"\"\"\n\ndef fill_complectation_item(value):\n    if item in value:\n        return 1\n    else:\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for item in most_frequent_items:\n    data[item] = data['complectation'].apply(fill_complectation_item)\n\ndata.drop(['complectation'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3.5 Возраст машины"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['years_old'] = 2021 - data['productionDate']\ndata.drop(['productionDate'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3.6 Преобразуем категориальные признаки"},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in ['bodyType', 'brand', 'color', 'fuelType', 'model_name', 'vehicleTransmission', \n               'ПТС', 'Привод', 'Руль']:\n    data[column] = data[column].astype('category').cat.codes\n\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(10).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.4 Проверим корреляцию"},{"metadata":{},"cell_type":"markdown","source":"### 1.4.1 Посмотрим на корреляцию признаков, полученных из complectation"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_corr = []\ncolumns_corr = most_frequent_items.copy()\ncolumns_corr.append('price')\ndata_corr = data.query('sample == 1')[columns_corr].corr()\n\nplt.figure(figsize=(20, 12))\nsns.heatmap(data_corr[(data_corr >= 0.6) | (data_corr <= 0)], annot=True, cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(data_corr['price'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Выводы:\n\nЗаметим, что признаки **airbag-driver**, **electro-window-front**, **abs**, **immo**, **lock**, **airbag-passenger**, **electro-mirrors**, **computer**, **airbag-side**, **front-seats-heat** коррелируют между собой больше чем на 0.6\nОставим один из них, который больше коррелирует с **price** - **airbag-side**\n\nТак же, сильно коррелируют признаки **wheel-configuration1** и **wheel-configuration2**. Оставим один из них - **wheel-configuration1**\n\nПризнак **wheel-configuration1** коррелирует с **mirrors-heat**. Признак **mirrors-heat** коррелирует с **esp**. Удаляем **mirrors-heat**\n\nЕще несколько скоррлированных между собой признаков: **airbag-curtain**, **airbag-side**, **multi-wheel**, **wheel-leather**. Среди них оставляем **airbag-curtain**\n\nДалее, коррелируют **third-rear-headrest** и **seat-transformation**. Оставляем **third-rear-headrest**\n\nИ еще пара признаков: **airbag-curtain** и **isofix**. Оставляем **airbag-curtain**"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_drop = ['airbag-driver', 'electro-window-front', 'abs', 'immo', 'lock', 'airbag-passenger', \n                'electro-mirrors', 'front-seats-heat', 'wheel-configuration2', 'mirrors-heat', 'computer', \n                'airbag-side', 'multi-wheel', 'wheel-leather', 'seat-transformation', 'isofix']\n\ndata.drop(columns_drop, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in columns_drop:\n    columns_corr.remove(col)\n\ndata_corr = data.query('sample == 1')[columns_corr].corr()\n\nplt.figure(figsize=(20, 12))\nsns.heatmap(data_corr, annot=True, cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.4.2 Корреляция числовых признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = ['engine', 'enginePower', 'mileage', 'years_old', 'price']\n\ndata_corr = data.query('sample == 1')[num_cols].corr()\n\nplt.figure(figsize=(20, 12))\nsns.heatmap(data_corr, annot=True, cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Выводы:\n\nОбъем (engine) и мощность (enginePower) двигателя сильно скоррелированы между собой. Но оба коррелируют с ценой, так что оставим.\n\nТак же, есть корреляция между возрастом машины (years_old) и пробегом (mileage). Что вполне логично. Но оба признака все равно оставим"},{"metadata":{"papermill":{"duration":0.035737,"end_time":"2020-10-26T12:47:03.826552","exception":false,"start_time":"2020-10-26T12:47:03.790815","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 1.5 Готовим данные для моделей"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\n\nX = data.query('sample == 1').drop(['sample', 'price'], axis=1)\n#X_std = pd.DataFrame(data=scaler.fit_transform(X), columns=X.columns)\n\nX_sub = data.query('sample == 0').drop(['sample', 'price'], axis=1)\n#X_sub_std = pd.DataFrame(data=scaler.fit_transform(X_sub), columns=X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_sub.sample(10).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data.query('sample == 1')['price']","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:03.90948Z","iopub.status.busy":"2020-10-26T12:47:03.908518Z","iopub.status.idle":"2020-10-26T12:47:03.923409Z","shell.execute_reply":"2020-10-26T12:47:03.922602Z"},"papermill":{"duration":0.059208,"end_time":"2020-10-26T12:47:03.923564","exception":false,"start_time":"2020-10-26T12:47:03.864356","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Моделирование\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"Функция для вывода времени обучения модели и точности метрики MAPE\"\"\"\n\ndef print_learn_report(start, y_test, y_pred):\n    print('\\nВремя выполнения - ', datetime.now() - start)\n    print(f\"Точность по метрике MAPE:{(mape(y_test, y_pred))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.1 CatBoost"},{"metadata":{"papermill":{"duration":0.035833,"end_time":"2020-10-26T12:47:04.149539","exception":false,"start_time":"2020-10-26T12:47:04.113706","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### 2.1.1 Fit"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:04.256865Z","iopub.status.busy":"2020-10-26T12:47:04.248328Z","iopub.status.idle":"2020-10-26T12:48:12.17834Z","shell.execute_reply":"2020-10-26T12:48:12.17762Z"},"papermill":{"duration":67.991521,"end_time":"2020-10-26T12:48:12.178488","exception":false,"start_time":"2020-10-26T12:47:04.186967","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# start = datetime.now()\n# \n# model = CatBoostRegressor(iterations = 5000,\n#                           random_seed = RANDOM_SEED,\n#                           eval_metric='MAPE',\n#                           custom_metric=['R2', 'MAE'],\n#                           silent=True)\n# \n# model.fit(X_train, y_train,\n#          eval_set=(X_test, y_test),\n#          verbose_eval=0,\n#          use_best_model=True)\n# \n# model.save_model('catboost_single_model.model')\n# \n# predict = model.predict(X_test)\n# \n# # оцениваем точность\n# print_learn_report(start, y_test, predict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Время выполнения -  0:00:31.666172\n    Точность по метрике MAPE:14.49%"},{"metadata":{},"cell_type":"markdown","source":"### 2.1.2 Log Traget\nПопробуем взять таргет в логорифм - это позволит уменьшить влияние выбросов на обучение модели (используем для этого np.log и np.exp).    "},{"metadata":{"trusted":true},"cell_type":"code","source":"np.log(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# start = datetime.now()\n#  \n# cbr_model = CatBoostRegressor(iterations = 5000,\n#                               random_seed = RANDOM_SEED,\n#                               eval_metric='MAPE',\n#                               custom_metric=['R2', 'MAE'],\n#                               silent=True)\n#  \n# cbr_model.fit(X_train, np.log(y_train),         \n#               eval_set=(X_test, np.log(y_test)),\n#               verbose_eval=0,\n#               use_best_model=True)\n# \n# cbr_model.save_model('catboost_single_model_2_with_log.model')\n#  \n# predict_cbr = np.exp(cbr_model.predict(X_test))\n#  \n# # оцениваем точность\n# print_learn_report(start, y_test, predict_cbr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Время выполнения -  0:00:31.803131\n    Точность по метрике MAPE:12.54%"},{"metadata":{},"cell_type":"markdown","source":"## 2.2 RandomForest"},{"metadata":{},"cell_type":"markdown","source":"### 2.2.1 Fit"},{"metadata":{"trusted":true},"cell_type":"code","source":"# start = datetime.now()\n# \n# model = RandomForestRegressor(random_state = RANDOM_SEED,  n_jobs = -1)\n# model.fit(X_train, np.log(y_train))\n# \n# predict_rfr = np.exp(model.predict(X_test))\n# print_learn_report(start, y_test, predict_rfr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Время выполнения -  0:00:09.213073\n    Точность по метрике MAPE:13.21%"},{"metadata":{},"cell_type":"markdown","source":"### 2.2.2 Подберем гиперпараметры"},{"metadata":{"trusted":true},"cell_type":"code","source":"# rf_param = {'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)],\n#             'max_features': ['auto', 'sqrt'],\n#             'max_depth': [int(x) for x in np.linspace(1, 20, num = 2)] + [None],\n#             'min_samples_split': [2, 5, 10],\n#             'min_samples_leaf': [1, 2, 4],\n#             'bootstrap': [True, False]}\n#  \n# rfr = RandomForestRegressor(random_state = RANDOM_SEED)\n#  \n# rf_random = RandomizedSearchCV(estimator = rfr, \n#                                param_distributions = rf_param, \n#                                n_iter = 100, \n#                                cv = 3, \n#                                verbose=10, \n#                                random_state=RANDOM_SEED, \n#                                n_jobs = -1)\n# \n# rf_random.fit(X_train, np.log(y_train))\n# rf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**best_params_:**\n\n    {'n_estimators': 1000,\n     'min_samples_split': 5,\n     'min_samples_leaf': 1,\n     'max_features': 'auto',\n     'max_depth': 20,\n     'bootstrap': True}"},{"metadata":{"trusted":true},"cell_type":"code","source":"# start = datetime.now()\n# \n# best_rfr = RandomForestRegressor(random_state=RANDOM_SEED,\n#                                  n_estimators=1000,\n#                                  min_samples_split=5,\n#                                  min_samples_leaf=1,\n#                                  max_features='auto',\n#                                  max_depth=20,\n#                                  bootstrap=True)\n# \n# best_rfr.fit(X_train, np.log(y_train))\n# \n# predict_rfr = np.exp(best_rfr.predict(X_test))\n# print_learn_report(start, y_test, predict_rfr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Время выполнения -  0:03:11.127381\n    Точность по метрике MAPE:13.16%"},{"metadata":{},"cell_type":"markdown","source":"## 2.3 GradientBoostingRegressor"},{"metadata":{},"cell_type":"markdown","source":"### 2.3.1 Fit"},{"metadata":{"trusted":true},"cell_type":"code","source":"# start = datetime.now()\n# \n# model = GradientBoostingRegressor(random_state=RANDOM_SEED)\n# model.fit(X_train, np.log(y_train))\n# \n# predict_gbr = np.exp(model.predict(X_test))\n# print_learn_report(start, y_test, predict_gbr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Время выполнения -  0:00:05.745046\n    Точность по метрике MAPE:17.10%"},{"metadata":{},"cell_type":"markdown","source":"### 2.3.2 Подберем гиперпараметры"},{"metadata":{"trusted":true},"cell_type":"code","source":"# param_gbr = {'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)],\n#              'max_features': ['auto', 'sqrt', 'log2'],\n#              'max_depth': [int(x) for x in np.linspace(1, 20, num = 2)] + [None],\n#              'min_samples_split': [2, 5, 10],\n#              'min_samples_leaf': [1, 2, 4]}\n# \n# gbr = GradientBoostingRegressor()\n# \n# gbr_random = RandomizedSearchCV(estimator = gbr, \n#                                 param_distributions = param_gbr, \n#                                 n_iter = 100, \n#                                 cv = 3, \n#                                 verbose=10, \n#                                 random_state=RANDOM_SEED, \n#                                 n_jobs = -1)\n# \n# gbr_random.fit(X_train, np.log(y_train))\n# gbr_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**best_params_:**\n\n    {'n_estimators': 800,\n     'min_samples_split': 5,\n     'min_samples_leaf': 4,\n     'max_features': 'log2',\n     'max_depth': 20}"},{"metadata":{"trusted":true},"cell_type":"code","source":"# start = datetime.now()\n# \n# best_gbr = GradientBoostingRegressor(random_state=RANDOM_SEED,\n#                                      n_estimators=800,\n#                                      min_samples_split=5,\n#                                      min_samples_leaf=4,\n#                                      max_features='log2',\n#                                      max_depth=20)\n# \n# best_gbr.fit(X_train, np.log(y_train))\n# \n# predict_gbr = np.exp(best_gbr.predict(X_test))\n# print_learn_report(start, y_test, predict_gbr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Время выполнения -  0:00:51.461018\n    Точность по метрике MAPE:14.21%"},{"metadata":{},"cell_type":"markdown","source":"## 2.4 AdaBoostRegressor"},{"metadata":{},"cell_type":"markdown","source":"### 2.4.1 Fit"},{"metadata":{"trusted":true},"cell_type":"code","source":"# start = datetime.now()\n# \n# abr_model = AdaBoostRegressor(random_state=RANDOM_SEED)\n# abr_model.fit(X_train, np.log(y_train))\n# \n# abr_predict = np.exp(abr_model.predict(X_test))\n# print_learn_report(start, y_test, abr_predict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Время выполнения -  0:00:03.171050\n    Точность по метрике MAPE:29.59%"},{"metadata":{},"cell_type":"markdown","source":"### 2.4.2 Подберем гиперпараметры\n\nДля этого несколько раз выполним блоки представленного ниже кода, подбирая каждый параметр по отдельности, так как все вместе выполняет очень долго"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Сначала переберем параметры n_estimators и learning_rate\n# \n# abr_rezult = pd.DataFrame(columns = ['base_estimator', 'n_estimators', 'learning_rate', 'loss', 'MAPE'])\n# \n# param_abr = {'n_estimators': [int(x) for x in range(50, 550, 50)],\n#              'learning_rate':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1]}\n# \n# for n in param_abr['n_estimators']:\n#     for learning_rate in param_abr['learning_rate']:\n#         abr_model = AdaBoostRegressor(n_estimators=n,\n#                                       learning_rate=learning_rate,\n#                                       random_state=RANDOM_SEED)\n#                 \n#         abr_model.fit(X_train, np.log(y_train))\n#                 \n#         predict_abr = np.exp(abr_model.predict(X_test))\n#         abr_rezult.loc[len(abr_rezult)] = pd.Series(abr_model.get_params())\n#         abr_rezult.loc[len(abr_rezult)-1, 'MAPE'] = (mape(y_test, predict_abr))*100\n# \n# abr_rezult[abr_rezult['MAPE'] == abr_rezult['MAPE'].min()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    base_estimator = None\n    n_estimators = 200\n    learning_rate = 0.1\n    loss = linear\n    MAPE = 28.751902"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Теперь переберем отдельно learning_rate\n# \n# for learning_rate in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n#     abr_model = AdaBoostRegressor(n_estimators=200,\n#                                 learning_rate=learning_rate,\n#                                 random_state=RANDOM_SEED)\n#                 \n#     abr_model.fit(X_train, np.log(y_train))\n#                 \n#     predict_abr = np.exp(abr_model.predict(X_test))\n#     abr_rezult.loc[len(abr_rezult)] = pd.Series(abr_model.get_params())\n#     abr_rezult.loc[len(abr_rezult)-1, 'MAPE'] = (mape(y_test, predict_abr))*100\n# \n# abr_rezult[abr_rezult['MAPE'] == abr_rezult['MAPE'].min()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    base_estimator = None\n    n_estimators = 200\n    learning_rate = 0.2\n    loss = linear\n    MAPE = 28.585192"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # К уже поборанным параметрам подберем параметр loss\n#\n# for loss in ['linear', 'square', 'exponential']:\n#     abr_model = AdaBoostRegressor(n_estimators=200,\n#                                 learning_rate=0.2,\n#                                 loss=loss,\n#                                 random_state=RANDOM_SEED)\n#                 \n#     abr_model.fit(X_train, np.log(y_train))\n#                 \n#     predict_abr = np.exp(abr_model.predict(X_test))\n#     abr_rezult.loc[len(abr_rezult)] = pd.Series(abr_model.get_params())\n#     abr_rezult.loc[len(abr_rezult)-1, 'MAPE'] = (mape(y_test, predict_abr))*100\n# \n# abr_rezult[abr_rezult['MAPE'] == abr_rezult['MAPE'].min()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    base_estimator = None\n    n_estimators = 200\n    learning_rate = 0.2\n    loss = exponential\n    MAPE = 28.369335"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Снова переберем параметры n_estimators и learning_rate\n# \n# param_abr = {'n_estimators': [int(x) for x in range(50, 550, 50)],\n#              'learning_rate':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n# \n# for n in param_abr['n_estimators']:\n#     for learning_rate in param_abr['learning_rate']:\n#         abr_model = AdaBoostRegressor(n_estimators=n,\n#                                       learning_rate=learning_rate,\n#                                       loss='exponential',\n#                                       random_state=RANDOM_SEED)\n#                 \n#         abr_model.fit(X_train, np.log(y_train))\n#                 \n#         predict_abr = np.exp(abr_model.predict(X_test))\n#         abr_rezult.loc[len(abr_rezult)] = pd.Series(abr_model.get_params())\n#         abr_rezult.loc[len(abr_rezult)-1, 'MAPE'] = (mape(y_test, predict_abr))*100\n# \n# abr_rezult[abr_rezult['MAPE'] == abr_rezult['MAPE'].min()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Теперь переберем отдельно learning_rate\n# \n# for learning_rate in [0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39]:\n#     abr_model = AdaBoostRegressor(n_estimators=200,\n#                                 loss='exponential',\n#                                 learning_rate=learning_rate,\n#                                 random_state=RANDOM_SEED)\n#                 \n#     abr_model.fit(X_train, np.log(y_train))\n#                 \n#     predict_abr = np.exp(abr_model.predict(X_test))\n#     abr_rezult.loc[len(abr_rezult)] = pd.Series(abr_model.get_params())\n#     abr_rezult.loc[len(abr_rezult)-1, 'MAPE'] = (mape(y_test, predict_abr))*100\n# \n# abr_rezult[abr_rezult['MAPE'] == abr_rezult['MAPE'].min()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    base_estimator = None\n    n_estimators = 100\n    learning_rate = 0.33\n    loss = exponential\n    MAPE = 27.885213"},{"metadata":{},"cell_type":"markdown","source":"## 2.5 Стеккинг"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\n \nestimators=[('best_rfr', RandomForestRegressor(random_state=RANDOM_SEED,\n                                                n_estimators=1000,\n                                                min_samples_split=5,\n                                                min_samples_leaf=1,\n                                                max_features='auto',\n                                                max_depth=20,\n                                                bootstrap=True)),\n             ('best_gbr', GradientBoostingRegressor(random_state=RANDOM_SEED,\n                                                    n_estimators=800,\n                                                    min_samples_split=5,\n                                                    min_samples_leaf=4,\n                                                    max_features='log2',\n                                                    max_depth=20)),\n             ('model_ctb', CatBoostRegressor(iterations=5000,\n                                             random_seed=RANDOM_SEED,\n                                             eval_metric='MAPE',\n                                             custom_metric=['R2','MAE'],\n                                             silent=True))]\n  \nst_ensemble = StackingRegressor(estimators=estimators,\n                                final_estimator=LinearRegression(normalize=True, n_jobs=-1),\n                                n_jobs=-1,\n                                cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED))\n     \nst_ensemble.fit(X_train, np.log(y_train))\n  \npredict_ensemble = np.exp(st_ensemble.predict(X_test))\nprint_learn_report(start, y_test, predict_ensemble)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.085876,"end_time":"2020-10-26T12:48:12.734207","exception":false,"start_time":"2020-10-26T12:48:12.648331","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Submission"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:48:13.227584Z","iopub.status.busy":"2020-10-26T12:48:13.226285Z","iopub.status.idle":"2020-10-26T12:48:13.762529Z","shell.execute_reply":"2020-10-26T12:48:13.763259Z"},"papermill":{"duration":0.628302,"end_time":"2020-10-26T12:48:13.763488","exception":false,"start_time":"2020-10-26T12:48:13.135186","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# predict_submission = np.exp(st_ensemble.predict(X_sub))\n# \n# sample_submission['price'] = predict_submission\n# sample_submission.to_csv(f'submission_2_v{VERSION}.csv', index=False)\n# sample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.087712,"end_time":"2020-10-26T12:48:14.104388","exception":false,"start_time":"2020-10-26T12:48:14.016676","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# What's next?\nИли что еще можно сделать, чтоб улучшить результат:\n\n* Спарсить свежие данные \n* Посмотреть, что можно извлечь из признаков или как еще можно обработать признаки\n* Сгенерировать новые признаки\n* Попробовать подобрать параметры модели\n* Попробовать другие алгоритмы и библиотеки ML\n* Сделать Ансамбль моделей, Blending, Stacking"},{"metadata":{},"cell_type":"markdown","source":"Подробный чек лист: https://docs.google.com/spreadsheets/d/1I_ErM3U0Cs7Rs1obyZbIEGtVn-H47pHNCi4xdDgUmXY/edit?usp=sharing"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}